import React, { useState, useRef, useCallback } from 'react';
import { Button, Space, Typography, Alert } from 'antd';

const { Text } = Typography;

// AudioWorkletå¤„ç†å™¨ä»£ç 
const workletCode = `
class PCMRecorderProcessor extends AudioWorkletProcessor {
  constructor(options) {
    super();
    this.bufferSize = options.processorOptions?.bufferSize || 4096;
    this.sampleRate = options.processorOptions?.sampleRate || 44100;
    this.sharedBuffer = null;
    this.writeIndex = 0;
    this.isRecording = false;
    
    this.port.onmessage = (event) => {
      const { type, sharedBuffer } = event.data;
      
      if (type === 'init-buffer') {
        this.sharedBuffer = new Float32Array(sharedBuffer);
        this.writeIndex = 0;
      } else if (type === 'start') {
        this.isRecording = true;
        this.writeIndex = 0;
      } else if (type === 'stop') {
        this.isRecording = false;
        this.port.postMessage({ 
          type: 'recording-stopped', 
          samplesRecorded: this.writeIndex 
        });
      }
    };
  }
  
  process(inputs, outputs, parameters) {
    if (!this.isRecording || !this.sharedBuffer || inputs.length === 0) {
      return true;
    }
    
    const input = inputs[0];
    if (input.length === 0) return true;
    
    // è·å–ç¬¬ä¸€ä¸ªå£°é“çš„æ•°æ®
    const channelData = input[0];
    
    // å°†éŸ³é¢‘æ•°æ®å†™å…¥å…±äº«ç¼“å†²åŒº
    for (let i = 0; i < channelData.length; i++) {
      if (this.writeIndex < this.sharedBuffer.length) {
        this.sharedBuffer[this.writeIndex] = channelData[i];
        this.writeIndex++;
      } else {
        // ç¼“å†²åŒºæ»¡äº†ï¼Œé€šçŸ¥ä¸»çº¿ç¨‹
        this.port.postMessage({ 
          type: 'buffer-full', 
          samplesRecorded: this.writeIndex 
        });
        this.isRecording = false;
        break;
      }
    }
    
    return true;
  }
}

registerProcessor('pcm-recorder-processor', PCMRecorderProcessor);
`;

const ClaudePCMAudioRecorder = () => {
    const [isRecording, setIsRecording] = useState(false);
    const [isSupported, setIsSupported] = useState(true);
    const [error, setError] = useState(null);
    const [recordedSamples, setRecordedSamples] = useState(0);

    const audioContextRef = useRef(null);
    const workletNodeRef = useRef(null);
    const streamRef = useRef(null);
    const sharedBufferRef = useRef(null);
    const recordedDataRef = useRef(null);

    // æ£€æŸ¥æµè§ˆå™¨æ”¯æŒ
    React.useEffect(() => {
        const checkSupport = () => {
            const supported =
                typeof AudioContext !== 'undefined' &&
                typeof AudioWorkletNode !== 'undefined' &&
                typeof SharedArrayBuffer !== 'undefined';

            setIsSupported(supported);

            if (!supported) {
                setError('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒAudioWorkletæˆ–SharedArrayBuffer');
            }
        };

        checkSupport();
    }, []);

    // åˆå§‹åŒ–éŸ³é¢‘ä¸Šä¸‹æ–‡å’Œå·¥ä½œå™¨
    const initializeAudio = useCallback(async () => {
        try {
            // åˆ›å»ºéŸ³é¢‘ä¸Šä¸‹æ–‡
            audioContextRef.current = new AudioContext();

            // åˆ›å»ºAudioWorkletæ¨¡å—
            const blob = new Blob([workletCode], { type: 'application/javascript' });
            const workletUrl = URL.createObjectURL(blob);
            await audioContextRef.current.audioWorklet.addModule(workletUrl);
            URL.revokeObjectURL(workletUrl);

            // è·å–åª’ä½“æµ
            streamRef.current = await navigator.mediaDevices.getUserMedia({
                audio: {
                    sampleRate: 44100,
                    channelCount: 1,
                    echoCancellation: false,
                    noiseSuppression: false,
                    autoGainControl: false
                }
            });

            // åˆ›å»ºéŸ³é¢‘æº
            const source = audioContextRef.current.createMediaStreamSource(streamRef.current);

            // åˆ›å»ºå…±äº«ç¼“å†²åŒº (10ç§’çš„éŸ³é¢‘æ•°æ®)
            const bufferSize = 44100 * 10; // 10ç§’ @ 44.1kHz
            sharedBufferRef.current = new SharedArrayBuffer(bufferSize * 4); // Float32 = 4 bytes
            recordedDataRef.current = new Float32Array(sharedBufferRef.current);

            // åˆ›å»ºAudioWorkletèŠ‚ç‚¹
            workletNodeRef.current = new AudioWorkletNode(
                audioContextRef.current,
                'pcm-recorder-processor',
                {
                    processorOptions: {
                        bufferSize: 4096,
                        sampleRate: 44100
                    }
                }
            );

            // ç›‘å¬å·¥ä½œå™¨æ¶ˆæ¯
            workletNodeRef.current.port.onmessage = (event) => {
                const { type, samplesRecorded } = event.data;

                if (type === 'recording-stopped' || type === 'buffer-full') {
                    setRecordedSamples(samplesRecorded);
                    if (type === 'buffer-full') {
                        setError('å½•éŸ³ç¼“å†²åŒºå·²æ»¡ï¼Œå½•éŸ³è‡ªåŠ¨åœæ­¢');
                    }
                    stopRecording();
                }
            };

            // åˆå§‹åŒ–å…±äº«ç¼“å†²åŒº
            workletNodeRef.current.port.postMessage({
                type: 'init-buffer',
                sharedBuffer: sharedBufferRef.current
            });

            // è¿æ¥éŸ³é¢‘èŠ‚ç‚¹
            source.connect(workletNodeRef.current);
            workletNodeRef.current.connect(audioContextRef.current.destination);

        } catch (err) {
            setError('åˆå§‹åŒ–éŸ³é¢‘å¤±è´¥: ' + err.message);
            throw err;
        }
    }, []);

    // å¼€å§‹å½•éŸ³
    const startRecording = useCallback(async () => {
        try {
            setError(null);
            setRecordedSamples(0);

            if (!audioContextRef.current) {
                await initializeAudio();
            }

            // æ¢å¤éŸ³é¢‘ä¸Šä¸‹æ–‡
            if (audioContextRef.current.state === 'suspended') {
                await audioContextRef.current.resume();
            }

            // å¼€å§‹å½•éŸ³
            workletNodeRef.current.port.postMessage({ type: 'start' });
            setIsRecording(true);

        } catch (err) {
            setError('å¼€å§‹å½•éŸ³å¤±è´¥: ' + err.message);
        }
    }, [initializeAudio]);

    // åœæ­¢å½•éŸ³
    const stopRecording = useCallback(() => {
        if (workletNodeRef.current && isRecording) {
            workletNodeRef.current.port.postMessage({ type: 'stop' });
        }
        setIsRecording(false);
    }, [isRecording]);

    // è·å–å½•åˆ¶çš„PCMæ•°æ®
    const getRecordedData = useCallback(() => {
        if (!recordedDataRef.current || recordedSamples === 0) {
            return null;
        }

        // è¿”å›å®é™…å½•åˆ¶çš„æ•°æ®åˆ‡ç‰‡
        return recordedDataRef.current.slice(0, recordedSamples);
    }, [recordedSamples]);

    // ç»„ä»¶å¸è½½æ—¶æ¸…ç†èµ„æº
    React.useEffect(() => {
        return () => {
            if (streamRef.current) {
                streamRef.current.getTracks().forEach(track => track.stop());
            }
            if (audioContextRef.current) {
                audioContextRef.current.close();
            }
        };
    }, []);

    if (!isSupported) {
        return (
            <Alert
                message="æµè§ˆå™¨ä¸æ”¯æŒ"
                description="æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒAudioWorkletæˆ–SharedArrayBufferåŠŸèƒ½"
                type="error"
                showIcon
            />
        );
    }

    return (
        <div style={{ padding: '20px', maxWidth: '400px' }}>
            <Space direction="vertical" size="middle" style={{ width: '100%' }}>
                <Space>
                    <Button
                        type={isRecording ? "default" : "primary"}
                        onClick={startRecording}
                        disabled={isRecording}
                        size="large"
                    >
                        å¼€å§‹å½•éŸ³
                    </Button>

                    <Button
                        type="primary"
                        danger
                        onClick={stopRecording}
                        disabled={!isRecording}
                        size="large"
                    >
                        åœæ­¢å½•éŸ³
                    </Button>
                </Space>

                {isRecording && (
                    <Text type="success">ğŸ”´ æ­£åœ¨å½•éŸ³ä¸­...</Text>
                )}

                {recordedSamples > 0 && (
                    <div>
                        <Text>å·²å½•åˆ¶æ ·æœ¬æ•°: {recordedSamples.toLocaleString()}</Text>
                        <br />
                        <Text type="secondary">
                            å½•åˆ¶æ—¶é•¿: {(recordedSamples / 44100).toFixed(2)} ç§’
                        </Text>
                    </div>
                )}

                {error && (
                    <Alert
                        message={error}
                        type="error"
                        showIcon
                        closable
                        onClose={() => setError(null)}
                    />
                )}

                {recordedSamples > 0 && (
                    <Button
                        onClick={() => {
                            const data = getRecordedData();
                            if (data) {
                                console.log('PCMæ•°æ®:', data);
                                console.log('æ•°æ®é•¿åº¦:', data.length);
                                console.log('é‡‡æ ·ç‡: 44.1kHz, å•å£°é“, 32ä½æµ®ç‚¹');
                                alert(`PCMæ•°æ®å·²è¾“å‡ºåˆ°æ§åˆ¶å°\næ ·æœ¬æ•°: ${data.length}\næ—¶é•¿: ${(data.length / 44100).toFixed(2)}ç§’`);
                            }
                        }}
                    >
                        è·å–PCMæ•°æ®
                    </Button>
                )}
            </Space>
        </div>
    );
};

export default ClaudePCMAudioRecorder;
